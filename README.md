# Local AI Chat powered by LM Studio API

This project allows you to run a local AI chat application using the LM Studio API. Follow the steps below to set up and start the application.

---

## ğŸš€ Installation and Setup

### 1. Clone the Repository
Clone this repository to your local directory:
```bash
git clone <repository-url>
cd <repository-name>
```

### 2. Install Dependencies
Run the following command to install the required dependencies:
```bash
npm install
```

### 3. Start the Development Server
Start the development server with:
```bash
npm run dev
```

---

## ğŸ§  Setting Up LM Studio

1. **Start LM Studio**  
   Open the LM Studio application on your computer.

2. **Load a Model**  
   Load a model of your choice in LM Studio.

3. **Enable CORS**  
   Navigate to the LM Studio local server and enable Cross-Origin Resource Sharing (CORS) to allow requests from the chat application.

---

## ğŸƒâ€â™‚ï¸ Running the Server

After completing the above steps, your local server should be up and running, ready to handle requests.

---

ğŸ‰ Enjoy exploring the local AI chat functionality!